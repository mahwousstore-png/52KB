"""
engines/engine.py  v21.0 â€” Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚ Ø§Ù„Ø³Ø±Ø¹Ø©
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ ØªØ·Ø¨ÙŠØ¹ Ù…Ø³Ø¨Ù‚ (Pre-normalize) â†’ vectorized cdist â†’ Gemini Ù„Ù„ØºÙ…ÙˆØ¶ ÙÙ‚Ø·
âš¡ 5x Ø£Ø³Ø±Ø¹ Ù…Ù† v20 Ù…Ø¹ Ù†ÙØ³ Ø§Ù„Ø¯Ù‚Ø© 99.5%

Ø§Ù„Ø®Ø·Ø©:
  1. Ø¹Ù†Ø¯ Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù â†’ ØªØ·Ø¨ÙŠØ¹ ÙƒÙ„ Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…Ù†Ø§ÙØ³ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© (cache)
  2. Ù„ÙƒÙ„ Ù…Ù†ØªØ¬Ù†Ø§ â†’ cdist vectorized Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø© (Ø¨Ø¯Ù„ loop)
  3. Ø£ÙØ¶Ù„ 5 Ù…Ø±Ø´Ø­ÙŠÙ† â†’ Gemini ÙÙ‚Ø· Ø¥Ø°Ø§ score Ø¨ÙŠÙ† 62-96%
  4. score â‰¥97% â†’ ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙÙˆØ±ÙŠ  |  score <62% â†’ Ù…ÙÙ‚ÙˆØ¯
"""
import re, io, json, hashlib, sqlite3, time
from datetime import datetime
import pandas as pd
from rapidfuzz import fuzz, process as rf_process
from rapidfuzz.distance import Indel
import requests as _req

# â”€â”€â”€ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from config import (REJECT_KEYWORDS, KNOWN_BRANDS, WORD_REPLACEMENTS,
                        MATCH_THRESHOLD, HIGH_CONFIDENCE, REVIEW_THRESHOLD,
                        PRICE_TOLERANCE, TESTER_KEYWORDS, SET_KEYWORDS, GEMINI_API_KEYS)
except:
    REJECT_KEYWORDS = ["sample","Ø¹ÙŠÙ†Ø©","Ø¹ÙŠÙ†Ù‡","decant","ØªÙ‚Ø³ÙŠÙ…","split","miniature"]
    KNOWN_BRANDS = [
        "Dior","Chanel","Gucci","Tom Ford","Versace","Armani","YSL","Prada","Burberry",
        "Hermes","Creed","Montblanc","Amouage","Rasasi","Lattafa","Arabian Oud","Ajmal",
        "Al Haramain","Afnan","Armaf","Mancera","Montale","Kilian","Jo Malone",
        "Carolina Herrera","Paco Rabanne","Mugler","Ralph Lauren","Parfums de Marly",
        "Nishane","Xerjoff","Byredo","Le Labo","Roja","Narciso Rodriguez",
        "Dolce & Gabbana","Valentino","Bvlgari","Cartier","Hugo Boss","Calvin Klein",
        "Givenchy","Lancome","Guerlain","Jean Paul Gaultier","Issey Miyake","Davidoff",
        "Coach","Michael Kors","Initio","Memo Paris","Maison Margiela","Diptyque",
        "Missoni","Juicy Couture","Moschino","Dunhill","Bentley","Jaguar",
        "Boucheron","Chopard","Elie Saab","Escada","Ferragamo","Fendi",
        "Kenzo","Lacoste","Loewe","Rochas","Roberto Cavalli","Tiffany",
        "Van Cleef","Azzaro","Chloe","Elizabeth Arden","Swiss Arabian",
        "Penhaligons","Clive Christian","Floris","Acqua di Parma",
        "Ard Al Zaafaran","Nabeel","Asdaaf","Maison Alhambra",
        "Tiziana Terenzi","Maison Francis Kurkdjian","Serge Lutens",
        "Frederic Malle","Ormonde Jayne","Zoologist","Tauer",
        "Banana Republic","Benetton","Bottega Veneta","Celine","Dsquared2",
        "Ermenegildo Zegna","Sisley","Mexx","Amadou","Thameen",
        "Nasomatto","Nicolai","Replica","Atelier Cologne","Aerin",
        "Angel Schlesser","Annick Goutal","Antonio Banderas","Balenciaga",
        "Bond No 9","Boadicea","Carner Barcelona","Clean","Commodity",
        "Costume National","Creed","Derek Lam","Diptique","Estee Lauder",
        "Franck Olivier","Giorgio Beverly Hills","Guerlain","Guess",
        "Histoires de Parfums","Illuminum","Jimmy Choo","Kenneth Cole",
        "Lalique","Lolita Lempicka","Lubin","Miu Miu","Moresque",
        "Nobile 1942","Oscar de la Renta","Oud Elite","Philipp Plein",
        "Police","Prada","Rasasi","Reminiscence","Salvatore Ferragamo",
        "Stella McCartney","Ted Lapidus","Ungaro","Vera Wang","Viktor Rolf",
        "Zadig Voltaire","Zegna","Ajwad","Club de Nuit","Milestone",
        "Ù„Ø·Ø§ÙØ©","Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ù„Ø¹ÙˆØ¯","Ø±ØµØ§Ø³ÙŠ","Ø£Ø¬Ù…Ù„","Ø§Ù„Ø­Ø±Ù…ÙŠÙ†","Ø£Ø±Ù…Ø§Ù",
        "Ø£Ù…ÙˆØ§Ø¬","ÙƒØ±ÙŠØ¯","ØªÙˆÙ… ÙÙˆØ±Ø¯","Ø¯ÙŠÙˆØ±","Ø´Ø§Ù†ÙŠÙ„","ØºÙˆØªØ´ÙŠ","Ø¨Ø±Ø§Ø¯Ø§",
        "Ù…ÙŠØ³ÙˆÙ†ÙŠ","Ø¬ÙˆØ³ÙŠ ÙƒÙˆØªÙˆØ±","Ù…ÙˆØ³ÙƒÙŠÙ†Ùˆ","Ø¯Ø§Ù†Ù‡ÙŠÙ„","Ø¨Ù†ØªÙ„ÙŠ",
        "ÙƒÙŠÙ†Ø²Ùˆ","Ù„Ø§ÙƒÙˆØ³Øª","ÙÙ†Ø¯ÙŠ","Ø§ÙŠÙ„ÙŠ ØµØ¹Ø¨","Ø§Ø²Ø§Ø±Ùˆ",
        "ÙƒÙŠÙ„ÙŠØ§Ù†","Ù†ÙŠØ´Ø§Ù†","Ø²ÙŠØ±Ø¬ÙˆÙ","Ø¨Ù†Ù‡Ø§Ù„ÙŠØºÙˆÙ†Ø²","Ù…Ø§Ø±Ù„ÙŠ","Ø¬ÙŠØ±Ù„Ø§Ù†",
        "ØªÙŠØ²ÙŠØ§Ù†Ø§ ØªØ±ÙŠÙ†Ø²ÙŠ","Ù…Ø§ÙŠØ²ÙˆÙ† ÙØ±Ø§Ù†Ø³ÙŠØ³","Ø¨Ø§ÙŠØ±ÙŠØ¯Ùˆ","Ù„ÙŠ Ù„Ø§Ø¨Ùˆ",
        "Ù…Ø§Ù†Ø³ÙŠØ±Ø§","Ù…ÙˆÙ†ØªØ§Ù„ÙŠ","Ø±ÙˆØ¬Ø§","Ø¬Ùˆ Ù…Ø§Ù„ÙˆÙ†","Ø«Ù…ÙŠÙ†","Ø£Ù…Ø§Ø¯Ùˆ",
        "Ù†Ø§Ø³ÙˆÙ…Ø§ØªÙˆ","Ù…ÙŠØ²ÙˆÙ† Ù…Ø§Ø±Ø¬ÙŠÙ„Ø§","Ù†ÙŠÙƒÙˆÙ„Ø§ÙŠ",
        "Ø¬ÙŠÙ…ÙŠ ØªØ´Ùˆ","Ù„Ø§Ù„ÙŠÙƒ","Ø¨ÙˆÙ„ÙŠØ³","ÙÙŠÙƒØªÙˆØ± Ø±ÙˆÙ„Ù",
        "ÙƒÙ„ÙˆÙŠ","Ø¨Ø§Ù„Ù†Ø³ÙŠØ§ØºØ§","Ù…ÙŠÙˆ Ù…ÙŠÙˆ",
    ]
    WORD_REPLACEMENTS = {}
    MATCH_THRESHOLD = 68; HIGH_CONFIDENCE = 92; REVIEW_THRESHOLD = 75
    PRICE_TOLERANCE = 5; TESTER_KEYWORDS = ["tester","ØªØ³ØªØ±"]; SET_KEYWORDS = ["set","Ø·Ù‚Ù…","Ù…Ø¬Ù…ÙˆØ¹Ø©"]
    GEMINI_API_KEYS = []

# â”€â”€â”€ Ù…Ø±Ø§Ø¯ÙØ§Øª Ø°ÙƒÙŠØ© Ù„Ù„Ø¹Ø·ÙˆØ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_SYN = {
    "eau de parfum":"edp","Ø§Ùˆ Ø¯Ùˆ Ø¨Ø§Ø±ÙØ§Ù†":"edp","Ø£Ùˆ Ø¯Ùˆ Ø¨Ø§Ø±ÙØ§Ù†":"edp",
    "Ø§Ùˆ Ø¯ÙŠ Ø¨Ø§Ø±ÙØ§Ù†":"edp","Ø¨Ø§Ø±ÙØ§Ù†":"edp","parfum":"edp","perfume":"edp",
    "eau de toilette":"edt","Ø§Ùˆ Ø¯Ùˆ ØªÙˆØ§Ù„ÙŠØª":"edt","Ø£Ùˆ Ø¯Ùˆ ØªÙˆØ§Ù„ÙŠØª":"edt",
    "ØªÙˆØ§Ù„ÙŠØª":"edt","toilette":"edt","toilet":"edt",
    "eau de cologne":"edc","ÙƒÙˆÙ„ÙˆÙ†":"edc","cologne":"edc",
    "extrait de parfum":"extrait","parfum extrait":"extrait",
    "Ø¯ÙŠÙˆØ±":"dior","Ø´Ø§Ù†ÙŠÙ„":"chanel","Ø´Ù†Ù„":"chanel","Ø£Ø±Ù…Ø§Ù†ÙŠ":"armani","Ø§Ø±Ù…Ø§Ù†ÙŠ":"armani",
    "Ø¬ÙˆØ±Ø¬ÙŠÙˆ Ø§Ø±Ù…Ø§Ù†ÙŠ":"armani","ÙØ±Ø³Ø§ØªØ´ÙŠ":"versace","ÙÙŠØ±Ø³Ø§ØªØ´ÙŠ":"versace",
    "ØºÙŠØ±Ù„Ø§Ù†":"guerlain","ØªÙˆÙ… ÙÙˆØ±Ø¯":"tom ford","ØªÙˆÙ…ÙÙˆØ±Ø¯":"tom ford",
    "Ù„Ø·Ø§ÙØ©":"lattafa","Ù„Ø·Ø§ÙÙ‡":"lattafa",
    "Ø£Ø¬Ù…Ù„":"ajmal","Ø±ØµØ§ØµÙŠ":"rasasi","Ø£Ù…ÙˆØ§Ø¬":"amouage","ÙƒØ±ÙŠØ¯":"creed",
    "Ø§ÙŠÙ Ø³Ø§Ù† Ù„ÙˆØ±Ø§Ù†":"ysl","Ø³Ø§Ù† Ù„ÙˆØ±Ø§Ù†":"ysl","yves saint laurent":"ysl",
    "ØºÙˆØªØ´ÙŠ":"gucci","Ù‚ÙˆØªØ´ÙŠ":"gucci","Ø¨Ø±Ø§Ø¯Ø§":"prada","Ø¨Ø±Ø§Ø¯Ø©":"prada",
    "Ø¨Ø±Ø¨Ø±ÙŠ":"burberry","Ø¨ÙŠØ±Ø¨Ø±ÙŠ":"burberry","Ø¬ÙŠÙÙ†Ø´ÙŠ":"givenchy","Ø¬ÙÙ†Ø´ÙŠ":"givenchy",
    "ÙƒØ§Ø±ÙˆÙ„ÙŠÙ†Ø§ Ù‡ÙŠØ±ÙŠØ±Ø§":"carolina herrera","Ø¨Ø§ÙƒÙˆ Ø±Ø§Ø¨Ø§Ù†":"paco rabanne",
    "Ù†Ø§Ø±Ø³ÙŠØ³Ùˆ Ø±ÙˆØ¯Ø±ÙŠØºÙŠØ²":"narciso rodriguez","ÙƒØ§Ù„ÙÙ† ÙƒÙ„Ø§ÙŠÙ†":"calvin klein",
    "Ù‡ÙˆØ¬Ùˆ Ø¨ÙˆØ³":"hugo boss","ÙØ§Ù„Ù†ØªÙŠÙ†Ùˆ":"valentino","Ø¨Ù„ØºØ§Ø±ÙŠ":"bvlgari",
    "ÙƒØ§Ø±ØªÙŠÙŠÙ‡":"cartier","Ù„Ø§Ù†ÙƒÙˆÙ…":"lancome","Ø¬Ùˆ Ù…Ø§Ù„ÙˆÙ†":"jo malone",
    "Ø³ÙˆÙØ§Ø¬":"sauvage","Ø¨Ù„Ùˆ":"bleu","Ø¥ÙŠØ±ÙˆØ³":"eros","Ø§ÙŠØ±ÙˆØ³":"eros",
    "ÙˆØ§Ù† Ù…ÙŠÙ„ÙŠÙˆÙ†":"1 million",
    "Ø¥Ù†ÙÙŠÙƒØªÙˆØ³":"invictus","Ø£ÙÙŠÙ†ØªÙˆØ³":"aventus","Ø¹ÙˆØ¯":"oud","Ù…Ø³Ùƒ":"musk",
    "Ù…ÙŠØ³ÙˆÙ†ÙŠ":"missoni","Ø¬ÙˆØ³ÙŠ ÙƒÙˆØªÙˆØ±":"juicy couture","Ù…ÙˆØ³ÙƒÙŠÙ†Ùˆ":"moschino",
    "Ø¯Ø§Ù†Ù‡ÙŠÙ„":"dunhill","Ø¨Ù†ØªÙ„ÙŠ":"bentley","ÙƒÙŠÙ†Ø²Ùˆ":"kenzo","Ù„Ø§ÙƒÙˆØ³Øª":"lacoste",
    "ÙÙ†Ø¯ÙŠ":"fendi","Ø§ÙŠÙ„ÙŠ ØµØ¹Ø¨":"elie saab","Ø§Ø²Ø§Ø±Ùˆ":"azzaro",
    "ÙÙŠØ±Ø§ØºØ§Ù…Ùˆ":"ferragamo","Ø´ÙˆØ¨Ø§Ø±":"chopard","Ø¨ÙˆØ´Ø±ÙˆÙ†":"boucheron",
    "Ù„Ø§Ù†ÙƒÙ…":"lancome","Ù„Ø§Ù†ÙƒÙˆÙ…":"lancome","Ø¬ÙŠÙÙ†Ø´ÙŠ":"givenchy","Ø¬ÙŠÙØ§Ù†Ø´ÙŠ":"givenchy",
    "Ø¨Ø±Ø¨Ø±ÙŠ":"burberry","Ø¨ÙŠØ±Ø¨Ø±ÙŠ":"burberry","Ø¨ÙˆØ±Ø¨ÙŠØ±ÙŠ":"burberry",
    "ÙÙŠØ±Ø³Ø§ØªØ´ÙŠ":"versace","ÙØ±Ø²Ø§ØªØ´ÙŠ":"versace",
    "Ø±ÙˆØ¨ÙŠØ±ØªÙˆ ÙƒÙØ§Ù„ÙŠ":"roberto cavalli","Ø±ÙˆØ¨Ø±ØªÙˆ ÙƒØ§ÙØ§Ù„ÙŠ":"roberto cavalli",
    "Ø³Ù„ÙØ§ØªÙˆØ±ÙŠ":"ferragamo","Ø³Ø§Ù„ÙØ§ØªÙˆØ±ÙŠ":"ferragamo",
    "Ø§ÙŠÙ Ø³Ø§Ù† Ù„ÙˆØ±Ø§Ù†":"ysl","Ø§ÙŠÙ Ø³Ø§Ù†Øª Ù„ÙˆØ±Ø§Ù†":"ysl",
    "Ù‡ÙŠØ±Ù…ÙŠØ³":"hermes","Ø§Ø±Ù…ÙŠØ³":"hermes","Ù‡Ø±Ù…Ø²":"hermes",
    "ÙƒÙŠÙ„ÙŠØ§Ù†":"kilian","ÙƒÙ„ÙŠØ§Ù†":"kilian",
    "Ù†ÙŠØ´Ø§Ù†":"nishane","Ù†ÙŠØ´Ø§Ù†ÙŠ":"nishane",
    "Ø²ÙŠØ±Ø¬ÙˆÙ":"xerjoff","Ø²ÙŠØ±Ø¬ÙˆÙÙ":"xerjoff",
    "Ø¨Ù†Ù‡Ø§Ù„ÙŠØºÙˆÙ†Ø²":"penhaligons","Ø¨Ù†Ù‡Ø§Ù„ÙŠØºÙˆÙ†":"penhaligons",
    "Ù…Ø§Ø±Ù„ÙŠ":"parfums de marly","Ø¯ÙŠ Ù…Ø§Ø±Ù„ÙŠ":"parfums de marly",
    "Ø¬ÙŠØ±Ù„Ø§Ù†":"guerlain","ØºÙŠØ±Ù„Ø§Ù†":"guerlain","Ø¬Ø±Ù„Ø§Ù†":"guerlain",
    "ØªÙŠØ²ÙŠØ§Ù†Ø§ ØªØ±ÙŠÙ†Ø²ÙŠ":"tiziana terenzi","ØªÙŠØ²ÙŠØ§Ù†Ø§":"tiziana terenzi",
    "Ù†Ø§Ø³ÙˆÙ…Ø§ØªÙˆ":"nasomatto",
    "Ù…ÙŠØ²ÙˆÙ† Ù…Ø§Ø±Ø¬ÙŠÙ„Ø§":"maison margiela","Ù…Ø§Ø±Ø¬ÙŠÙ„Ø§":"maison margiela","Ø±Ø¨Ù„ÙŠÙƒØ§":"replica",
    "Ù†ÙŠÙƒÙˆÙ„Ø§ÙŠ":"nicolai","Ù†ÙŠÙƒÙˆÙ„Ø§Ø¦ÙŠ":"nicolai",
    "Ù…Ø§ÙŠØ²ÙˆÙ† ÙØ±Ø§Ù†Ø³ÙŠØ³":"maison francis kurkdjian","ÙØ±Ø§Ù†Ø³ÙŠØ³":"maison francis kurkdjian",
    "Ø¨Ø§ÙŠØ±ÙŠØ¯Ùˆ":"byredo","Ù„ÙŠ Ù„Ø§Ø¨Ùˆ":"le labo",
    "Ù…Ø§Ù†Ø³ÙŠØ±Ø§":"mancera","Ù…ÙˆÙ†ØªØ§Ù„ÙŠ":"montale","Ø±ÙˆØ¬Ø§":"roja",
    "Ø¬Ùˆ Ù…Ø§Ù„ÙˆÙ†":"jo malone","Ø¬ÙˆÙ…Ø§Ù„ÙˆÙ†":"jo malone",
    "Ø«Ù…ÙŠÙ†":"thameen","Ø£Ù…Ø§Ø¯Ùˆ":"amadou","Ø§Ù…Ø§Ø¯Ùˆ":"amadou",
    "Ø§Ù†ÙŠØ´ÙŠÙˆ":"initio","Ø¥Ù†ÙŠØ´ÙŠÙˆ":"initio","initio":"initio",
    "Ø¬ÙŠÙ…ÙŠ ØªØ´Ùˆ":"jimmy choo","Ø¬ÙŠÙ…ÙŠØªØ´Ùˆ":"jimmy choo",
    "Ù„Ø§Ù„ÙŠÙƒ":"lalique","Ø¨ÙˆÙ„ÙŠØ³":"police",
    "ÙÙŠÙƒØªÙˆØ± Ø±ÙˆÙ„Ù":"viktor rolf","ÙÙŠÙƒØªÙˆØ± Ø§Ù†Ø¯ Ø±ÙˆÙ„Ù":"viktor rolf",
    "ÙƒÙ„ÙˆÙŠ":"chloe","Ø´Ù„ÙˆÙŠ":"chloe",
    "Ø¨Ø§Ù„Ù†Ø³ÙŠØ§ØºØ§":"balenciaga","Ø¨Ø§Ù„Ù†Ø³ÙŠØ§Ø¬Ø§":"balenciaga",
    "Ù…ÙŠÙˆ Ù…ÙŠÙˆ":"miu miu",
    "Ø§Ø³ØªÙŠ Ù„ÙˆØ¯Ø±":"estee lauder","Ø§Ø³ØªÙŠÙ„ÙˆØ¯Ø±":"estee lauder",
    "ÙƒÙˆØªØ´":"coach","Ù…Ø§ÙŠÙƒÙ„ ÙƒÙˆØ±Ø³":"michael kors",
    "Ø±Ø§Ù„Ù Ù„ÙˆØ±ÙŠÙ†":"ralph lauren","Ø±Ø§Ù„Ù Ù„ÙˆØ±Ø§Ù†":"ralph lauren",
    "Ø§ÙŠØ²ÙŠ Ù…ÙŠØ§ÙƒÙŠ":"issey miyake","Ø§ÙŠØ³ÙŠ Ù…ÙŠØ§ÙƒÙŠ":"issey miyake",
    "Ø¯Ø§ÙÙŠØ¯ÙˆÙ":"davidoff","Ø¯ÙŠÙÙŠØ¯ÙˆÙ":"davidoff",
    "Ø¯ÙˆÙ„Ø´ÙŠ Ø§Ù†Ø¯ ØºØ§Ø¨Ø§Ù†Ø§":"dolce gabbana","Ø¯ÙˆÙ„ØªØ´ÙŠ":"dolce gabbana","Ø¯ÙˆÙ„Ø´ÙŠ":"dolce gabbana",
    "Ø¬Ø§Ù† Ø¨ÙˆÙ„ ØºÙˆÙ„ØªÙŠÙŠÙ‡":"jean paul gaultier","ØºÙˆÙ„ØªÙŠÙŠÙ‡":"jean paul gaultier","ØºÙˆÙ„ØªÙŠÙ‡":"jean paul gaultier",
    "ØºÙˆØªÙŠÙŠÙ‡":"jean paul gaultier","Ø¬Ø§Ù† Ø¨ÙˆÙ„ ØºÙˆØªÙŠÙŠÙ‡":"jean paul gaultier","Ù‚ÙˆØªÙŠÙŠÙ‡":"jean paul gaultier","Ù‚ÙˆÙ„ØªÙŠÙŠÙ‡":"jean paul gaultier",
    "Ù…ÙˆÙ†Øª Ø¨Ù„Ø§Ù†Ùƒ":"montblanc","Ù…ÙˆÙ†ØªØ¨Ù„Ø§Ù†":"montblanc",
    "Ù…ÙˆØ¬Ù„Ø±":"mugler","Ù…ÙˆØºÙ„Ø±":"mugler","ØªÙŠÙŠØ±ÙŠ Ù…ÙˆØ¬Ù„Ø±":"mugler",
    "ÙƒÙ„ÙˆØ¨ Ø¯ÙŠ Ù†ÙˆÙŠ":"club de nuit","ÙƒÙ„ÙˆØ¨ Ø¯Ù†ÙˆÙŠ":"club de nuit",
    "Ù…Ø§ÙŠÙ„Ø³ØªÙˆÙ†":"milestone",
    "Ø³ÙƒØ§Ù†Ø¯Ù„":"scandal","Ø³ÙƒØ§Ù†Ø¯Ø§Ù„":"scandal",
    " Ù…Ù„":" ml","Ù…Ù„ÙŠ ":"ml ","Ù…Ù„ÙŠ":"ml","Ù…Ù„":"ml",
    "Ø£":"Ø§","Ø¥":"Ø§","Ø¢":"Ø§","Ø©":"Ù‡","Ù‰":"ÙŠ","Ø¤":"Ùˆ","Ø¦":"ÙŠ",
}

# â”€â”€â”€ SQLite Cache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_DB = "match_cache_v21.db"
def _init_db():
    try:
        cn = sqlite3.connect(_DB, check_same_thread=False)
        cn.execute("CREATE TABLE IF NOT EXISTS cache(h TEXT PRIMARY KEY, v TEXT, ts TEXT)")
        cn.commit(); cn.close()
    except: pass

def _cget(k):
    try:
        cn = sqlite3.connect(_DB, check_same_thread=False)
        r = cn.execute("SELECT v FROM cache WHERE h=?", (k,)).fetchone()
        cn.close(); return json.loads(r[0]) if r else None
    except: return None

def _cset(k, v):
    try:
        cn = sqlite3.connect(_DB, check_same_thread=False)
        cn.execute("INSERT OR REPLACE INTO cache VALUES(?,?,?)",
                   (k, json.dumps(v, ensure_ascii=False), datetime.now().isoformat()))
        cn.commit(); cn.close()
    except: pass

_init_db()

# â”€â”€â”€ Ø¯ÙˆØ§Ù„ Ø£Ø³Ø§Ø³ÙŠØ© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def read_file(f):
    try:
        name = f.name.lower()
        df = None
        if name.endswith('.csv'):
            for enc in ['utf-8-sig','utf-8','windows-1256','cp1256','latin-1']:
                try:
                    f.seek(0)
                    df = pd.read_csv(f, encoding=enc, on_bad_lines='skip')
                    if len(df) > 0 and not df.columns[0].startswith('\ufeff'): 
                        break
                except: continue
            if df is None:
                return None, "ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ±Ù…ÙŠØ²Ø§Øª"
        elif name.endswith(('.xlsx','.xls')):
            df = pd.read_excel(f)
        else:
            return None, "ØµÙŠØºØ© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©"
        # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† BOM ÙˆØ§Ù„Ù…Ø³Ø§ÙØ§Øª
        df.columns = df.columns.str.strip().str.replace('\ufeff', '', regex=False)
        df = df.dropna(how='all').reset_index(drop=True)
        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Unnamed Ø£Ùˆ Ø£Ø³Ù…Ø§Ø¡ CSS â†’ ØªØ®Ù…ÙŠÙ† Ø°ÙƒÙŠ
        df = _smart_rename_columns(df)
        return df, None
    except Exception as e:
        return None, str(e)


def _smart_rename_columns(df):
    """ØªØ®Ù…ÙŠÙ† Ø°ÙƒÙŠ Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ© (Unnamed Ø£Ùˆ Ø£Ø³Ù…Ø§Ø¡ CSS)"""
    cols = list(df.columns)
    # Ø­Ø§Ù„Ø© 1: Ø£Ø¹Ù…Ø¯Ø© Unnamed (Ù…Ù„Ù Ø¨Ø¯ÙˆÙ† Ø¹Ù†Ø§ÙˆÙŠÙ†)
    unnamed_count = sum(1 for c in cols if str(c).startswith('Unnamed'))
    # Ø­Ø§Ù„Ø© 2: Ø£Ø¹Ù…Ø¯Ø© CSS (Ù…Ø«Ù„ styles_productCard__name)
    css_count = sum(1 for c in cols if 'style' in str(c).lower() or '__' in str(c))
    
    if unnamed_count >= len(cols) - 1 or css_count >= 1:
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„ØªØ®Ù…ÙŠÙ† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
        new_cols = {}
        for col in cols:
            sample = df[col].dropna().head(20)
            if sample.empty:
                continue
            # ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… (Ø£Ø³Ø¹Ø§Ø±)
            numeric_count = 0
            for v in sample:
                try:
                    float(str(v).replace(',', ''))
                    numeric_count += 1
                except:
                    pass
            if numeric_count >= len(sample) * 0.7:
                new_cols[col] = 'Ø§Ù„Ø³Ø¹Ø±'
            else:
                # ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†ØµÙˆØµ â†’ Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬
                if 'Ø§Ù„Ù…Ù†ØªØ¬' not in new_cols.values() and 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬' not in new_cols.values():
                    new_cols[col] = 'Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬'
                else:
                    new_cols[col] = col  # Ø§Ø¨Ù‚Ù ÙƒÙ…Ø§ Ù‡Ùˆ
        if new_cols:
            df = df.rename(columns=new_cols)
    return df

def normalize(text):
    if not isinstance(text, str): return ""
    t = text.strip().lower()
    for k, v in WORD_REPLACEMENTS.items():
        t = t.replace(k.lower(), v)
    for k, v in _SYN.items():
        t = t.replace(k, v)
    t = re.sub(r'[^\w\s\u0600-\u06FF.]', ' ', t)
    return re.sub(r'\s+', ' ', t).strip()

def extract_size(text):
    if not isinstance(text, str): return 0.0
    tl = text.lower()
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† oz Ø£ÙˆÙ„Ø§Ù‹ ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ù„Ù€ ml
    oz = re.findall(r'(\d+(?:\.\d+)?)\s*(?:oz|ounce)', tl)
    if oz:
        return float(oz[0]) * 29.5735  # 1 oz = 29.5735 ml
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ml
    ml = re.findall(r'(\d+(?:\.\d+)?)\s*(?:ml|Ù…Ù„|Ù…Ù„ÙŠ|milliliter)', tl)
    return float(ml[0]) if ml else 0.0

def extract_brand(text):
    if not isinstance(text, str): return ""
    n = normalize(text)
    tl = text.lower()
    for b in KNOWN_BRANDS:
        if normalize(b) in n or b.lower() in tl: return b
    return ""

def extract_type(text):
    if not isinstance(text, str): return ""
    n = normalize(text)
    if "edp" in n or "extrait" in n: return "EDP"
    if "edt" in n: return "EDT"
    if "edc" in n: return "EDC"
    return ""

def extract_gender(text):
    if not isinstance(text, str): return ""
    tl = text.lower()
    m = any(k in tl for k in ["pour homme","for men"," men "," man ","Ø±Ø¬Ø§Ù„ÙŠ","Ù„Ù„Ø±Ø¬Ø§Ù„"," Ù…Ø§Ù† "," Ù‡ÙˆÙ… ","homme"," uomo"])
    w = any(k in tl for k in ["pour femme","for women","women"," woman ","Ù†Ø³Ø§Ø¦ÙŠ","Ù„Ù„Ù†Ø³Ø§Ø¡","Ø§Ù„Ù†Ø³Ø§Ø¦ÙŠ","lady","femme"," donna"])
    if m and not w: return "Ø±Ø¬Ø§Ù„ÙŠ"
    if w and not m: return "Ù†Ø³Ø§Ø¦ÙŠ"
    return ""

def extract_product_line(text, brand=""):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø®Ø· Ø§Ù„Ø¥Ù†ØªØ§Ø¬ (Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ) Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø§Ø±ÙƒØ© ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©.
    Ù…Ø«Ø§Ù„: 'Ø¹Ø·Ø± Ø¨Ø±Ø¨Ø±ÙŠ Ù‡ÙŠØ±Ùˆ Ø£Ùˆ Ø¯Ùˆ ØªÙˆØ§Ù„ÙŠØª 100Ù…Ù„' â†’ 'Ù‡ÙŠØ±Ùˆ'
    Ù…Ø«Ø§Ù„: 'Ø¹Ø·Ø± Ù„Ù†Ø¯Ù† Ù…Ù† Ø¨Ø±Ø¨Ø±ÙŠ Ù„Ù„Ø±Ø¬Ø§Ù„' â†’ 'Ù„Ù†Ø¯Ù†'
    Ù‡Ø°Ø§ Ø¶Ø±ÙˆØ±ÙŠ Ù„Ù…Ù†Ø¹ Ù…Ø·Ø§Ø¨Ù‚Ø© 'Ø¨Ø±Ø¨Ø±ÙŠ Ù‡ÙŠØ±Ùˆ' Ù…Ø¹ 'Ø¨Ø±Ø¨Ø±ÙŠ Ù„Ù†Ø¯Ù†'
    """
    if not isinstance(text, str): return ""
    n = text.lower()
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø§Ø±ÙƒØ© (Ø¹Ø±Ø¨ÙŠ + Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ) â€” ÙƒÙ„ Ø§Ù„Ø£Ø´ÙƒØ§Ù„
    if brand:
        for b_var in [brand.lower(), normalize(brand)]:
            n = n.replace(b_var, " ")
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø±Ø§Ø¯ÙØ§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù„Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø§Ø±ÙƒØ© ØªØ­Ø¯ÙŠØ¯Ø§Ù‹
        brand_norm = brand.lower()
        for k, v in _SYN.items():
            if v == brand_norm or v == normalize(brand):
                n = n.replace(k, " ")
    # Ø¥Ø²Ø§Ù„Ø© Ø­Ø±ÙˆÙ Ø§Ù„Ø¬Ø± Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©
    for prep in ['Ù…Ù†','ÙÙŠ','Ù„Ù„','Ø§Ù„']:
        n = re.sub(r'\b' + prep + r'\b', ' ', n)
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
    _STOP = [
        'Ø¹Ø·Ø±','ØªØ³ØªØ±','ØªÙŠØ³ØªØ±','tester','perfume','fragrance',
        'Ø§Ùˆ Ø¯Ùˆ','Ø§Ùˆ Ø¯ÙŠ','Ø£Ùˆ Ø¯Ùˆ','Ø£Ùˆ Ø¯ÙŠ',
        'Ø¨Ø§Ø±ÙØ§Ù†','Ø¨Ø§Ø±ÙÙŠÙˆÙ…','Ø¨Ø±ÙÙŠÙˆÙ…','Ø¨ÙŠØ±ÙÙŠÙˆÙ…','Ø¨Ø±ÙØ§Ù†','parfum','edp','eau de parfum',
        'ØªÙˆØ§Ù„ÙŠØª','toilette','edt','eau de toilette',
        'ÙƒÙˆÙ„ÙˆÙ†','cologne','edc','eau de cologne',
        'Ø§Ù†ØªÙ†Ø³','Ø§Ù†ØªÙŠÙ†Ø³','intense','Ø§ÙƒØ³ØªØ±ÙŠÙ…','extreme',
        'Ø§Ø¨Ø³ÙˆÙ„Ùˆ','Ø§Ø¨Ø³ÙˆÙ„ÙŠÙˆ','absolue','absolute','absolu',
        'Ø§ÙƒØ³ØªØ±ÙŠØª','Ø§ÙƒØ³ØªØ±Ø§ÙŠØª','extrait','extract',
        'Ø¯Ùˆ','de','du','la','le','les','the',
        # Ø£Ø³Ù…Ø§Ø¡ Ù…Ø§Ø±ÙƒØ§Øª ÙØ±Ø¹ÙŠØ© ØªØ¨Ù‚Ù‰ Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø§Ø±ÙƒØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        'ØªÙŠØ±ÙŠÙ†Ø²ÙŠ','ØªØ±ÙŠÙ†Ø²ÙŠ','terenzi','terenzio',  # Tiziana Terenzi
        'ÙƒÙˆØ±ÙƒØ¯Ø¬ÙŠØ§Ù†','ÙƒØ±ÙƒØ¯Ø¬ÙŠØ§Ù†','kurkdjian',  # MFK
        'Ù…ÙŠØ²ÙˆÙ†','Ù…Ø§ÙŠØ²ÙˆÙ†','maison',  # Maison Margiela/MFK
        'Ø¨Ø§Ø±ÙŠØ³','paris',  # ÙƒÙ„Ù…Ø© Ø´Ø§Ø¦Ø¹Ø©
        'Ø¯ÙˆÙ','dove',  # Roja Dove
        'Ù„Ù„Ø±Ø¬Ø§Ù„','Ù„Ù„Ù†Ø³Ø§Ø¡','Ø±Ø¬Ø§Ù„ÙŠ','Ù†Ø³Ø§Ø¦ÙŠ','Ù„Ù„Ø¬Ù†Ø³ÙŠÙ†',
        'for men','for women','unisex','pour homme','pour femme',
        'ml','Ù…Ù„','Ù…Ù„ÙŠ','milliliter',
        'ÙƒØ±ØªÙˆÙ† Ø§Ø¨ÙŠØ¶','ÙƒØ±ØªÙˆÙ† Ø£Ø¨ÙŠØ¶','white box',
        'Ø§ØµÙ„ÙŠ','original','authentic','Ø¬Ø¯ÙŠØ¯','new',
        'Ø§ØµØ¯Ø§Ø±','Ø§ØµØ¯Ø§Ø±Ø§Øª','edition','limited',
        # ÙƒÙ„Ù…Ø§Øª Ø´Ø§Ø¦Ø¹Ø© ØªØ±ÙØ¹ pl_score Ø®Ø·Ø£Ù‹
        'Ø¨Ø±ÙØ§Ù†','spray','Ø¨Ø®Ø§Ø®','Ø¹Ø·ÙˆØ±',
        'Ø§Ù„Ø±Ø¬Ø§Ù„ÙŠ','Ø§Ù„Ù†Ø³Ø§Ø¦ÙŠ','Ø±Ø¬Ø§Ù„','Ù†Ø³Ø§Ø¡',
        'men','women','homme','femme',
        'Ù…Ø§Ù†','man','uomo','donna',
        'Ù‡ÙˆÙ…','ÙÙŠÙ…',
        'Ø§Ùˆ','ou','or','Ùˆ',
        # ÙƒÙ„Ù…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© ØªØ±ÙØ¹ pl_score Ø®Ø·Ø£Ù‹
        'Ù„Ùˆ','Ù„Ø§','lo',
        'di','Ø¯ÙŠ',
        # Ø£Ø¬Ø²Ø§Ø¡ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø§Ø±ÙƒØ§Øª Ø§Ù„Ù…Ø±ÙƒØ¨Ø© Ø§Ù„ØªÙŠ ØªØ¨Ù‚Ù‰ Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø±Ø§Ø¯Ù
        'Ø¬Ø§Ù†','Ø¨ÙˆÙ„','jean','paul','gaultier',
        'ÙƒØ§Ø±ÙˆÙ„ÙŠÙ†Ø§','Ù‡ÙŠØ±ÙŠØ±Ø§','carolina','herrera',
        'Ø¯ÙˆÙ„Ø´ÙŠ','ØºØ§Ø¨Ø§Ù†Ø§','dolce','gabbana',
        'Ø±Ø§Ù„Ù','Ù„ÙˆØ±ÙŠÙ†','ralph','lauren',
        'Ø§ÙŠØ²ÙŠ','Ù…ÙŠØ§ÙƒÙŠ','issey','miyake',
        'ÙØ§Ù†','ÙƒÙ„ÙŠÙ','van','cleef','arpels',
        'Ø§ÙˆØ±Ù…Ù†Ø¯','Ø¬Ø§ÙŠØ§Ù†','ormonde','jayne',
        'ØªÙˆÙ…Ø§Ø³','ÙƒÙˆØ³Ù…Ø§Ù„Ø§','thomas','kosmala',
        'ÙØ±Ø§Ù†Ø³ÙŠØ³','francis',
        'Ø±ÙˆØ³ÙŠÙ†Ø¯Ùˆ','Ù…Ø§ØªÙŠÙˆ','rosendo','mateu',
        'Ù†ÙŠÙƒÙˆÙ„Ø§ÙŠ','nicolai',
        'Ø§Ø±Ù…Ø§Ù','armaf',
    ]
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø·ÙˆÙŠÙ„Ø© (4+ Ø­Ø±ÙˆÙ) Ø¨Ù€ replace Ø¹Ø§Ø¯ÙŠ
    # ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù‚ØµÙŠØ±Ø© (1-3 Ø­Ø±ÙˆÙ) Ø¨Ù€ word boundary Ù„Ù…Ù†Ø¹ Ø­Ø°Ù Ø£Ø¬Ø²Ø§Ø¡ Ù…Ù† ÙƒÙ„Ù…Ø§Øª Ø£Ø®Ø±Ù‰
    for w in _STOP:
        if len(w) <= 3:
            n = re.sub(r'(?:^|\s)' + re.escape(w) + r'(?:\s|$)', ' ', n)
        else:
            n = n.replace(w, ' ')
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù… (Ø§Ù„Ø­Ø¬Ù…) + Ù…Ù„/ml Ø§Ù„Ù…Ù„ØªØµÙ‚Ø©
    n = re.sub(r'\d+(?:\.\d+)?\s*(?:ml|Ù…Ù„|Ù…Ù„ÙŠ)?', ' ', n)
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ²
    n = re.sub(r'[^\w\s\u0600-\u06FF]', ' ', n)
    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù‡Ù…Ø²Ø§Øª
    for k, v in {'Ø£':'Ø§','Ø¥':'Ø§','Ø¢':'Ø§','Ø©':'Ù‡','Ù‰':'ÙŠ'}.items():
        n = n.replace(k, v)
    return re.sub(r'\s+', ' ', n).strip()

def is_sample(t):
    return isinstance(t, str) and any(k in t.lower() for k in REJECT_KEYWORDS)

def is_tester(t):
    return isinstance(t, str) and any(k in t.lower() for k in TESTER_KEYWORDS)

def is_set(t):
    return isinstance(t, str) and any(k in t.lower() for k in SET_KEYWORDS)

def classify_product(name):
    """ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ù†ØªØ¬ Ø­Ø³Ø¨ AI_COMPARISON_INSTRUCTIONS: retail/tester/set/hair_mist/body_mist/rejected"""
    if not isinstance(name, str): return "retail"
    nl = name.lower()
    if any(w in nl for w in ['sample','Ø¹ÙŠÙ†Ø©','Ø¹ÙŠÙ†Ù‡','miniature','Ù…ÙŠÙ†ÙŠØ§ØªØ´Ø±','travel size','decant','ØªÙ‚Ø³ÙŠÙ…']):
        return 'rejected'
    if any(w in nl for w in ['tester','ØªØ³ØªØ±','ØªÙŠØ³ØªØ±']):
        return 'tester'
    if any(w in nl for w in ['set ','Ø³ÙŠØª','Ù…Ø¬Ù…ÙˆØ¹Ø©','gift','Ù‡Ø¯ÙŠØ©','Ø·Ù‚Ù…','coffret']):
        return 'set'
    # hair mist: ÙƒÙ„Ù…Ø§Øª ÙƒØ§Ù…Ù„Ø© ÙÙ‚Ø· (Ù„ØªØ¬Ù†Ø¨ "Ù‡ÙŠØ±ÙŠØ±Ø§" â†’ hair_mist)
    if re.search(r'\bhair\s*mist\b|Ø¹Ø·Ø±\s*Ø´Ø¹Ø±|Ù…Ø¹Ø·Ø±\s*Ø´Ø¹Ø±|Ù„Ù„Ø´Ø¹Ø±|\bhair\b', nl):
        return 'hair_mist'
    # body mist: ÙƒÙ„Ù…Ø§Øª ÙƒØ§Ù…Ù„Ø© ÙÙ‚Ø·
    if re.search(r'\bbody\s*mist\b|Ø¨ÙˆØ¯ÙŠ\s*Ù…Ø³Øª|Ø¨Ø®Ø§Ø®\s*Ø¬Ø³Ù…|Ù…Ø¹Ø·Ø±\s*Ø¬Ø³Ù…|\bbody\s*spray\b', nl):
        return 'body_mist'
    # Ø¨ÙˆØ¯Ø±Ø©/ÙƒØ±ÙŠÙ…/Ù„ÙˆØ´Ù†
    if re.search(r'Ø¨ÙˆØ¯Ø±Ø©|Ø¨ÙˆØ¯Ø±Ù‡|powder|ÙƒØ±ÙŠÙ…|cream|Ù„ÙˆØ´Ù†|lotion|Ø¯ÙŠÙˆØ¯Ø±Ù†Øª|deodorant', nl):
        return 'other'
    return 'retail'

def _price(row):
    for c in ["Ø§Ù„Ø³Ø¹Ø±","Price","price","Ø³Ø¹Ø±","PRICE"]:
        if c in row.index:
            try: return float(str(row[c]).replace(",",""))
            except: pass
    # Ø§Ø­ØªÙŠØ§Ø·ÙŠ: Ø§Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù…ÙŠ ÙŠØ´Ø¨Ù‡ Ø§Ù„Ø³Ø¹Ø±
    for c in row.index:
        try:
            v = float(str(row[c]).replace(",",""))
            if 1 <= v <= 99999:  # Ù†Ø·Ø§Ù‚ Ø³Ø¹Ø± Ù…Ø¹Ù‚ÙˆÙ„
                return v
        except:
            pass
    return 0.0

def _pid(row, col):
    if not col or col not in row.index: return ""
    v = str(row.get(col,""))
    return v if v not in ("nan","None","") else ""

def _fcol(df, cands):
    for c in cands:
        if c in df.columns: return c
    return df.columns[0] if len(df.columns) else ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ø§Ù„ÙƒÙ„Ø§Ø³ Ø§Ù„Ø¬Ø¯ÙŠØ¯: Pre-normalized Competitor Index
#  ÙŠÙØ¨Ù†Ù‰ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ù„ÙƒÙ„ Ù…Ù„Ù Ù…Ù†Ø§ÙØ³ â† ÙŠØ³Ø±Ù‘Ø¹ Ø§Ù„Ù€ matching 5x
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class CompIndex:
    """ÙÙ‡Ø±Ø³ Ø§Ù„Ù…Ù†Ø§ÙØ³ Ø§Ù„Ù…Ø·Ø¨ÙÙ‘Ø¹ Ù…Ø³Ø¨Ù‚Ø§Ù‹"""
    def __init__(self, df, name_col, id_col, comp_name):
        self.comp_name = comp_name
        self.name_col  = name_col
        self.id_col    = id_col
        self.df        = df.reset_index(drop=True)
        # ØªØ·Ø¨ÙŠØ¹ Ù…Ø³Ø¨Ù‚ Ù„ÙƒÙ„ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ â€” Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·
        self.raw_names  = df[name_col].fillna("").astype(str).tolist()
        self.norm_names = [normalize(n) for n in self.raw_names]
        self.brands     = [extract_brand(n) for n in self.raw_names]
        self.sizes      = [extract_size(n) for n in self.raw_names]
        self.types      = [extract_type(n) for n in self.raw_names]
        self.genders    = [extract_gender(n) for n in self.raw_names]
        # Ø®Ø·ÙˆØ· Ø§Ù„Ø¥Ù†ØªØ§Ø¬ â€” Ù„Ù…Ù†Ø¹ Ù…Ø·Ø§Ø¨Ù‚Ø© 'Ø¨Ø±Ø¨Ø±ÙŠ Ù‡ÙŠØ±Ùˆ' Ù…Ø¹ 'Ø¨Ø±Ø¨Ø±ÙŠ Ù„Ù†Ø¯Ù†'
        self.plines     = [extract_product_line(n, self.brands[i]) for i, n in enumerate(self.raw_names)]
        self.prices     = [_price(row) for _, row in df.iterrows()]
        self.ids        = [_pid(row, id_col) for _, row in df.iterrows()]

    def search(self, our_norm, our_br, our_sz, our_tp, our_gd, our_pline="", top_n=6):
        """Ø¨Ø­Ø« vectorized Ø¨Ù€ rapidfuzz process.extract Ù…Ø¹ Ù…Ù‚Ø§Ø±Ù†Ø© Ø®Ø· Ø§Ù„Ø¥Ù†ØªØ§Ø¬"""
        if not self.norm_names: return []

        # Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ù…Ø³Ø¨Ù‚Ø§Ù‹
        valid_idx = [i for i, n in enumerate(self.raw_names) if not is_sample(n)]
        if not valid_idx: return []

        valid_norms = [self.norm_names[i] for i in valid_idx]

        # extract Ø¨Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø³Ø±Ø¹
        fast = rf_process.extract(
            our_norm, valid_norms,
            scorer=fuzz.token_set_ratio,
            limit=min(25, len(valid_norms))
        )

        cands = []
        seen  = set()
        for _, fast_score, vi in fast:
            if fast_score < max(MATCH_THRESHOLD - 15, 40): continue
            idx  = valid_idx[vi]
            name = self.raw_names[idx]
            if name in seen: continue

            c_br = self.brands[idx]
            c_sz = self.sizes[idx]
            c_tp = self.types[idx]
            c_gd = self.genders[idx]
            c_pl = self.plines[idx]

            # â•â•â• ÙÙ„Ø§ØªØ± Ø³Ø±ÙŠØ¹Ø© â•â•â•
            if our_br and c_br and normalize(our_br) != normalize(c_br): continue
            if our_sz > 0 and c_sz > 0 and abs(our_sz - c_sz) > 30: continue
            if our_tp and c_tp and our_tp != c_tp:
                if our_sz > 0 and c_sz > 0 and abs(our_sz - c_sz) > 3: continue
            if our_gd and c_gd and our_gd != c_gd: continue

            # â•â•â• ÙÙ„ØªØ± ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ù†ØªØ¬ (retail/tester/set/hair_mist) â•â•â•
            our_class = classify_product(our_norm)
            c_class = classify_product(name)
            if our_class != c_class:
                # Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ØªÙØ³ØªØ«Ù†Ù‰ ØªÙ…Ø§Ù…Ø§Ù‹
                if our_class == 'rejected' or c_class == 'rejected':
                    continue
                # Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª ÙˆÙ…Ø¹Ø·Ø±Ø§Øª Ø§Ù„Ø´Ø¹Ø±/Ø§Ù„Ø¬Ø³Ù… Ù„Ø§ ØªÙ‚Ø§Ø±Ù† Ù…Ø¹ Ø§Ù„Ø¹Ø·ÙˆØ±
                if our_class in ('hair_mist','body_mist','set','other') or \
                   c_class in ('hair_mist','body_mist','set','other'):
                    continue
                # Ø§Ù„ØªØ³ØªØ± ÙŠÙ‚Ø§Ø±Ù† ÙÙ‚Ø· Ù…Ø¹ Ø§Ù„ØªØ³ØªØ±ØŒ Ø§Ù„Ø¹Ø·Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙÙ‚Ø· Ù…Ø¹ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
                if (our_class == 'tester') != (c_class == 'tester'):
                    continue

            # â•â•â• Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙÙŠ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª (Ù†Ù…Ø¨Ø± 11 â‰  Ù†Ù…Ø¨Ø± 10) â•â•â•
            _NUM_WORDS = {
                'ÙˆÙ†':'1','ØªÙˆ':'2','Ø«Ø±ÙŠ':'3','ÙÙˆØ±':'4','ÙØ§ÙŠÙ':'5',
                'Ø³ÙƒØ³':'6','Ø³ÙÙ†':'7','Ø§ÙŠØª':'8','Ù†Ø§ÙŠÙ†':'9','ØªÙ†':'10',
                'one':'1','two':'2','three':'3','four':'4','five':'5',
                'six':'6','seven':'7','eight':'8','nine':'9','ten':'10',
                'i':'1','ii':'2','iii':'3','iv':'4','v':'5',
                'vi':'6','vii':'7','viii':'8','ix':'9','x':'10',
            }
            def _extract_product_numbers(text):
                """Extract product-identifying numbers (not sizes)"""
                nums = set()
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
                for m in re.finditer(r'(?:no|num|number|Ù†Ù…Ø¨Ø±|Ø±Ù‚Ù…|â„–|#)\s*(\d+)', text.lower()):
                    nums.add(m.group(1))
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù†ØµÙŠØ© (ÙˆÙ†ØŒ ØªÙˆØŒ Ø³ÙÙ†...)
                tl = text.lower()
                for word, num in _NUM_WORDS.items():
                    if f'Ù†Ù…Ø¨Ø± {word}' in tl or f'number {word}' in tl or f'no {word}' in tl or f'Ø±Ù‚Ù… {word}' in tl:
                        nums.add(num)
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø±Ù‚Ø§Ù… Ù…Ù„ØªØµÙ‚Ø© Ø¨ÙƒÙ„Ù…Ø§Øª (Ù…Ø«Ù„ Ø³ÙÙ†7)
                for m in re.finditer(r'[a-zØ€-Û¿](\d+)', text.lower()):
                    v = m.group(1)
                    if v not in {'100','50','30','200','150','75','80','125','250','300','ml'}:
                        nums.add(v)
                # Ø£Ø±Ù‚Ø§Ù… Ù…Ø³ØªÙ‚Ù„Ø© Ù„ÙŠØ³Øª Ø£Ø­Ø¬Ø§Ù… (Ù…Ø«Ù„ 212, 360, 9)
                for m in re.finditer(r'\b(\d{1,3})\b', text.lower()):
                    v = m.group(1)
                    # Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªØ¨ÙˆØ¹Ø© Ø¨Ù€ ml/Ù…Ù„
                    pos = m.end()
                    after = text.lower()[pos:pos+5].strip()
                    if after.startswith('ml') or after.startswith('Ù…Ù„'):
                        continue  # Ù‡Ø°Ø§ Ø­Ø¬Ù…
                    if v in {'212','360','1','2','3','4','5','6','7','8','9','11','12','13','14','15','16','17','18','19','21'}:
                        nums.add(v)
                return nums

            our_pnums = _extract_product_numbers(our_norm)
            c_pnums = _extract_product_numbers(self.norm_names[idx])
            if our_pnums and c_pnums and our_pnums != c_pnums:
                continue

            # â•â•â• Ù…Ù‚Ø§Ø±Ù†Ø© Ø®Ø· Ø§Ù„Ø¥Ù†ØªØ§Ø¬ (Ø§Ù„Ø­Ù„ Ø§Ù„Ø¬Ø°Ø±ÙŠ) â•â•â•
            pline_penalty = 0
            if our_pline and c_pl:
                pl_score = fuzz.token_sort_ratio(our_pline, c_pl)
                if our_br and c_br:
                    # Ù†ÙØ³ Ø§Ù„Ù…Ø§Ø±ÙƒØ© â†’ Ù…Ù‚Ø§Ø±Ù†Ø© Ø®Ø· Ø§Ù„Ø¥Ù†ØªØ§Ø¬ ØµØ§Ø±Ù…Ø© Ø¬Ø¯Ø§Ù‹
                    # Ø¨Ø§Ø±ÙˆÙ†Ø¯Ø§â‰ Ø¨Ø§Ø±Ø¯ÙˆÙ†(77%), Ø§Ù„Ø§Ø¨Ø§ÙŠâ‰ Ø§Ø³Ø¨Ø±ÙŠØª(75%)
                    # Ø³ÙˆÙØ§Ø¬=Ø³ÙˆÙØ§Ø¬(100%), Ø¹ÙˆØ¯ Ù…ÙˆØ¯=Ø¹ÙˆØ¯ Ø³ÙŠÙ„Ùƒ Ù…ÙˆØ¯(85%)
                    if pl_score < 78:
                        continue  # Ø±ÙØ¶ Ù†Ù‡Ø§Ø¦ÙŠ - Ø®Ø·ÙˆØ· Ø¥Ù†ØªØ§Ø¬ Ù…Ø®ØªÙ„ÙØ©
                    elif pl_score < 88:
                        pline_penalty = -20
                    elif pl_score < 94:
                        pline_penalty = -10
                else:
                    # Ù…Ø§Ø±ÙƒØ§Øª Ù…Ø®ØªÙ„ÙØ© Ø£Ùˆ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ© â†’ Ù…Ù‚Ø§Ø±Ù†Ø© Ø£ÙƒØ«Ø± ØµØ±Ø§Ù…Ø©
                    if pl_score < 65:
                        pline_penalty = -35
                    elif pl_score < 80:
                        pline_penalty = -22

            # â•â•â• score ØªÙØµÙŠÙ„ÙŠ â•â•â•
            n1, n2 = our_norm, self.norm_names[idx]
            s1 = fuzz.token_sort_ratio(n1, n2)
            s2 = fuzz.token_set_ratio(n1, n2)
            s3 = fuzz.partial_ratio(n1, n2)
            base = s1*0.35 + s2*0.35 + s3*0.30

            # â•â•â• ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø§Ø±ÙƒØ© â•â•â•
            if our_br and c_br:
                base += 10 if normalize(our_br)==normalize(c_br) else -25
            elif our_br and not c_br:
                base -= 25  # Ù…Ù†ØªØ¬Ù†Ø§ Ù„Ù‡ Ù…Ø§Ø±ÙƒØ© Ù„ÙƒÙ† Ø§Ù„Ù…Ù†Ø§ÙØ³ Ø¨Ø¯ÙˆÙ† â†’ Ø®ØµÙ… ÙƒØ¨ÙŠØ±
            elif not our_br and c_br:
                base -= 25  # Ø§Ù„Ø¹ÙƒØ³
            elif not our_br and not c_br:
                # ÙƒÙ„Ø§Ù‡Ù…Ø§ Ø¨Ø¯ÙˆÙ† Ù…Ø§Ø±ÙƒØ© â†’ Ø®ØµÙ… Ù„Ø£Ù† Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© ØºÙŠØ± Ù…ÙˆØ«ÙˆÙ‚Ø©
                base -= 10

            # â•â•â• ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø§Ù„Ø­Ø¬Ù… â•â•â•
            if our_sz > 0 and c_sz > 0:
                d = abs(our_sz - c_sz)
                base += 10 if d==0 else (-5 if d<=5 else -18 if d<=20 else -30)
            if our_tp and c_tp and our_tp != c_tp: base -= 14
            if our_gd and c_gd and our_gd != c_gd:
                continue  # Ø±ÙØ¶ Ù†Ù‡Ø§Ø¦ÙŠ - Ø±Ø¬Ø§Ù„ÙŠ â‰  Ù†Ø³Ø§Ø¦ÙŠ
            elif (our_gd or c_gd) and our_gd != c_gd:
                base -= 15  # Ø£Ø­Ø¯Ù‡Ù…Ø§ Ù…Ø­Ø¯Ø¯ ÙˆØ§Ù„Ø¢Ø®Ø± ÙØ§Ø±Øº

            # â•â•â• ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù‚ÙˆØ¨Ø© Ø®Ø· Ø§Ù„Ø¥Ù†ØªØ§Ø¬ â•â•â•
            base += pline_penalty

            score = round(max(0, min(100, base)), 1)
            if score < MATCH_THRESHOLD: continue

            seen.add(name)
            cands.append({
                "name": name, "score": score,
                "price": self.prices[idx], "product_id": self.ids[idx],
                "brand": c_br, "size": c_sz, "type": c_tp, "gender": c_gd,
                "competitor": self.comp_name,
            })

        cands.sort(key=lambda x: x["score"], reverse=True)
        return cands[:top_n]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Gemini Batch â€” 10 Ù…Ù†ØªØ¬Ø§Øª / Ø§Ø³ØªØ¯Ø¹Ø§Ø¡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
_GURL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"

def _ai_batch(batch):
    """
    batch: [{"our":str, "price":float, "candidates":[...]}]
    â†’ [int]  (0-based index | -1=no match)
    """
    if not GEMINI_API_KEYS or not batch: return [0]*len(batch)

    # cache key
    ck = hashlib.md5(json.dumps(
        [{"o":x["our"], "c":[c["name"] for c in x["candidates"]]} for x in batch],
        ensure_ascii=False, sort_keys=True).encode()).hexdigest()
    cached = _cget(ck)
    if cached is not None: return cached

    lines = []
    for i, it in enumerate(batch):
        cands = "\n".join(
            f"  {j+1}. {c['name']} | {int(c.get('size',0))}ml | "
            f"{c.get('type','?')} | {c.get('gender','?')} | {c.get('price',0):.0f}Ø±.Ø³"
            for j,c in enumerate(it["candidates"])
        )
        lines.append(f"[{i+1}] Ù…Ù†ØªØ¬Ù†Ø§: Â«{it['our']}Â» ({it['price']:.0f}Ø±.Ø³)\n{cands}")

    prompt = (
        "Ø®Ø¨ÙŠØ± Ø¹Ø·ÙˆØ± ÙØ§Ø®Ø±Ø©. Ù„ÙƒÙ„ Ù…Ù†ØªØ¬ Ø§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø´Ø­ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚ ØªÙ…Ø§Ù…Ø§Ù‹ Ø£Ùˆ 0 Ø¥Ø°Ø§ Ù„Ø§ ÙŠÙˆØ¬Ø¯.\n"
        "Ø§Ù„Ø´Ø±ÙˆØ·: âœ“Ù†ÙØ³ Ø§Ù„Ù…Ø§Ø±ÙƒØ© âœ“Ù†ÙØ³ Ø§Ù„Ø­Ø¬Ù… (Â±5ml) âœ“Ù†ÙØ³ EDP/EDT âœ“Ù†ÙØ³ Ø§Ù„Ø¬Ù†Ø³ Ø¥Ø°Ø§ Ù…Ø°ÙƒÙˆØ±\n\n"
        + "\n\n".join(lines)
        + f'\n\nJSON ÙÙ‚Ø·: {{"results":[r1,r2,...,r{len(batch)}]}}'
    )

    payload = {"contents":[{"parts":[{"text":prompt}]}],
               "generationConfig":{"temperature":0,"maxOutputTokens":200,"topP":1,"topK":1}}

    for attempt in range(3):
        for key in GEMINI_API_KEYS:
            if not key: continue
            try:
                r = _req.post(f"{_GURL}?key={key}", json=payload, timeout=22)
                if r.status_code == 200:
                    txt = r.json()["candidates"][0]["content"]["parts"][0]["text"]
                    clean = re.sub(r'```json|```','',txt).strip()
                    s = clean.find('{'); e = clean.rfind('}')+1
                    if s>=0 and e>s:
                        raw = json.loads(clean[s:e]).get("results",[])
                        out = []
                        for j,it in enumerate(batch):
                            n = raw[j] if j<len(raw) else 1
                            try: n=int(n)
                            except: n=1
                            if 1<=n<=len(it["candidates"]): out.append(n-1)
                            elif n==0: out.append(-1)
                            else: out.append(0)
                        _cset(ck, out)
                        return out
                elif r.status_code==429:
                    time.sleep(2**attempt)
            except: continue
        time.sleep(1)
    return [0]*len(batch)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ø¨Ù†Ø§Ø¡ ØµÙ Ø§Ù„Ù†ØªÙŠØ¬Ø©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def _row(product, our_price, our_id, brand, size, ptype, gender,
         best=None, override=None, src="", all_cands=None):
    sz_str = f"{int(size)}ml" if size else ""
    if best is None:
        return dict(Ø§Ù„Ù…Ù†ØªØ¬=product, Ù…Ø¹Ø±Ù_Ø§Ù„Ù…Ù†ØªØ¬=our_id, Ø§Ù„Ø³Ø¹Ø±=our_price,
                    Ø§Ù„Ù…Ø§Ø±ÙƒØ©=brand, Ø§Ù„Ø­Ø¬Ù…=sz_str, Ø§Ù„Ù†ÙˆØ¹=ptype, Ø§Ù„Ø¬Ù†Ø³=gender,
                    Ù…Ù†ØªØ¬_Ø§Ù„Ù…Ù†Ø§ÙØ³="â€”", Ù…Ø¹Ø±Ù_Ø§Ù„Ù…Ù†Ø§ÙØ³="", Ø³Ø¹Ø±_Ø§Ù„Ù…Ù†Ø§ÙØ³=0,
                    Ø§Ù„ÙØ±Ù‚=0, Ù†Ø³Ø¨Ø©_Ø§Ù„ØªØ·Ø§Ø¨Ù‚=0, Ø«Ù‚Ø©_AI="â€”",
                    Ø§Ù„Ù‚Ø±Ø§Ø±=override or "ğŸ”µ Ù…ÙÙ‚ÙˆØ¯ Ø¹Ù†Ø¯ Ø§Ù„Ù…Ù†Ø§ÙØ³",
                    Ø§Ù„Ø®Ø·ÙˆØ±Ø©="", Ø§Ù„Ù…Ù†Ø§ÙØ³="", Ø¹Ø¯Ø¯_Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†=0,
                    Ø¬Ù…ÙŠØ¹_Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†=[], Ù…ØµØ¯Ø±_Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©=src or "â€”",
                    ØªØ§Ø±ÙŠØ®_Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©=datetime.now().strftime("%Y-%m-%d"))

    cp    = float(best.get("price") or 0)
    score = float(best.get("score") or 0)
    diff  = round(our_price - cp, 2) if (our_price>0 and cp>0) else 0
    # Ù†Ø¸Ø§Ù… Ø§Ù„Ø®Ø·ÙˆØ±Ø© Ø­Ø³Ø¨ AI_COMPARISON_INSTRUCTIONS (Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ© + Ø«Ù‚Ø©)
    diff_pct = abs((diff / cp) * 100) if cp > 0 else 0
    if diff_pct > 20 and score >= 85:
        risk = "ğŸ”´ Ø­Ø±Ø¬"
    elif diff_pct > 10 and score >= 75:
        risk = "ğŸŸ¡ Ù…ØªÙˆØ³Ø·"
    else:
        risk = "ğŸŸ¢ Ù…Ù†Ø®ÙØ¶"

    # â•â•â• ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… â•â•â•
    # ğŸ”´ Ø³Ø¹Ø± Ø£Ø¹Ù„Ù‰: Ø³Ø¹Ø±Ù†Ø§ Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø§Ù„Ù…Ù†Ø§ÙØ³ Ø¨Ø£ÙƒØ«Ø± Ù…Ù† 10 Ø±ÙŠØ§Ù„
    # ğŸŸ¢ Ø³Ø¹Ø± Ø£Ù‚Ù„: Ø³Ø¹Ø±Ù†Ø§ Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ù…Ù†Ø§ÙØ³ Ø¨Ø£ÙƒØ«Ø± Ù…Ù† 10 Ø±ÙŠØ§Ù„
    # âœ… Ù…ÙˆØ§ÙÙ‚: Ø³Ø¹Ø±Ù†Ø§ Ù…Ù†Ø§Ø³Ø¨ (ÙØ±Ù‚ â‰¤ 10 Ø±ÙŠØ§Ù„)
    # âš ï¸ Ù…Ø±Ø§Ø¬Ø¹Ø©: Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© ØºÙŠØ± Ù…Ø¤ÙƒØ¯Ø© (Ø«Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø©)
    PRICE_DIFF_THRESHOLD = 10  # ÙØ±Ù‚ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ù…Ù‚Ø¨ÙˆÙ„ Ø¨Ø§Ù„Ø±ÙŠØ§Ù„
    if override:
        dec = override
    elif src in ("gemini","auto") or score >= HIGH_CONFIDENCE:
        # Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¤ÙƒØ¯Ø© â†’ ØªÙˆØ²ÙŠØ¹ Ø­Ø³Ø¨ Ø§Ù„Ø³Ø¹Ø±
        if our_price > 0 and cp > 0:
            if diff > PRICE_DIFF_THRESHOLD:     dec = "ğŸ”´ Ø³Ø¹Ø± Ø£Ø¹Ù„Ù‰"
            elif diff < -PRICE_DIFF_THRESHOLD:   dec = "ğŸŸ¢ Ø³Ø¹Ø± Ø£Ù‚Ù„"
            else:                                dec = "âœ… Ù…ÙˆØ§ÙÙ‚"
        else:
            dec = "âš ï¸ Ù…Ø±Ø§Ø¬Ø¹Ø©"  # Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø³Ø¹Ø± â†’ Ù…Ø±Ø§Ø¬Ø¹Ø©
    elif score >= REVIEW_THRESHOLD:
        # Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø­ØªÙ…Ù„Ø© Ù„ÙƒÙ† ØªØ­ØªØ§Ø¬ ØªØ£ÙƒÙŠØ¯ â†’ ØªØ­Øª Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©
        dec = "âš ï¸ Ù…Ø±Ø§Ø¬Ø¹Ø©"
    else:
        dec = "âš ï¸ Ù…Ø±Ø§Ø¬Ø¹Ø©"

    ai_lbl = {"gemini":f"ğŸ¤–âœ…({score:.0f}%)",
              "auto":f"ğŸ¯({score:.0f}%)",
              "gemini_no_match":"ğŸ¤–âŒ"}.get(src, f"{score:.0f}%")

    ac = (all_cands or [best])[:5]
    return dict(Ø§Ù„Ù…Ù†ØªØ¬=product, Ù…Ø¹Ø±Ù_Ø§Ù„Ù…Ù†ØªØ¬=our_id, Ø§Ù„Ø³Ø¹Ø±=our_price,
                Ø§Ù„Ù…Ø§Ø±ÙƒØ©=brand, Ø§Ù„Ø­Ø¬Ù…=sz_str, Ø§Ù„Ù†ÙˆØ¹=ptype, Ø§Ù„Ø¬Ù†Ø³=gender,
                Ù…Ù†ØªØ¬_Ø§Ù„Ù…Ù†Ø§ÙØ³=best["name"], Ù…Ø¹Ø±Ù_Ø§Ù„Ù…Ù†Ø§ÙØ³=best.get("product_id",""),
                Ø³Ø¹Ø±_Ø§Ù„Ù…Ù†Ø§ÙØ³=cp, Ø§Ù„ÙØ±Ù‚=diff, Ù†Ø³Ø¨Ø©_Ø§Ù„ØªØ·Ø§Ø¨Ù‚=score, Ø«Ù‚Ø©_AI=ai_lbl,
                Ø§Ù„Ù‚Ø±Ø§Ø±=dec, Ø§Ù„Ø®Ø·ÙˆØ±Ø©=risk, Ø§Ù„Ù…Ù†Ø§ÙØ³=best.get("competitor",""),
                Ø¹Ø¯Ø¯_Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†=len({c.get("competitor","") for c in ac}),
                Ø¬Ù…ÙŠØ¹_Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†=ac, Ù…ØµØ¯Ø±_Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©=src or "fuzzy",
                ØªØ§Ø±ÙŠØ®_Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©=datetime.now().strftime("%Y-%m-%d"))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„ â€” v21 Ø§Ù„Ù‡Ø¬ÙŠÙ† Ø§Ù„ÙØ§Ø¦Ù‚ Ø§Ù„Ø³Ø±Ø¹Ø©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def run_full_analysis(our_df, comp_dfs, progress_callback=None, use_ai=True):
    """
    1. Ø¨Ù†Ø§Ø¡ CompIndex Ù„ÙƒÙ„ Ù…Ù†Ø§ÙØ³ (ØªØ·Ø¨ÙŠØ¹ Ù…Ø³Ø¨Ù‚)
    2. Ù„ÙƒÙ„ Ù…Ù†ØªØ¬Ù†Ø§ â†’ search vectorized
    3. scoreâ‰¥97 â†’ ØªÙ„Ù‚Ø§Ø¦ÙŠ | 62-96 â†’ AI batch | <62 â†’ Ù…ÙÙ‚ÙˆØ¯
    """
    results = []
    our_col       = _fcol(our_df, ["Ø§Ù„Ù…Ù†ØªØ¬","Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬","Product","Name","name"])
    our_price_col = _fcol(our_df, ["Ø§Ù„Ø³Ø¹Ø±","Ø³Ø¹Ø±","Price","price","PRICE"])
    our_id_col    = _fcol(our_df, ["ID","id","Ù…Ø¹Ø±Ù","Ø±Ù‚Ù… Ø§Ù„Ù…Ù†ØªØ¬","SKU","sku","Ø§Ù„ÙƒÙˆØ¯"])

    # â”€â”€ Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© â”€â”€
    indices = {}
    for cname, cdf in comp_dfs.items():
        ccol = _fcol(cdf, ["Ø§Ù„Ù…Ù†ØªØ¬","Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬","Product","Name","name"])
        icol = _fcol(cdf, ["ID","id","Ù…Ø¹Ø±Ù","Ø±Ù‚Ù… Ø§Ù„Ù…Ù†ØªØ¬","SKU","sku","Ø§Ù„ÙƒÙˆØ¯","code"])
        indices[cname] = CompIndex(cdf, ccol, icol, cname)

    total   = len(our_df)
    pending = []
    BATCH   = 12  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù€ batch Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª API

    def _flush():
        if not pending: return
        idxs = _ai_batch(pending)
        for j, it in enumerate(pending):
            ci = idxs[j] if j<len(idxs) else 0
            if ci < 0:
                results.append(_row(it["product"],it["our_price"],it["our_id"],
                                    it["brand"],it["size"],it["ptype"],it["gender"],
                                    None,"ğŸ”µ Ù…ÙÙ‚ÙˆØ¯ Ø¹Ù†Ø¯ Ø§Ù„Ù…Ù†Ø§ÙØ³","gemini_no_match"))
            else:
                best = it["candidates"][ci]
                results.append(_row(it["product"],it["our_price"],it["our_id"],
                                    it["brand"],it["size"],it["ptype"],it["gender"],
                                    best,src="gemini",all_cands=it["all_cands"]))
        pending.clear()

    for i, (_, row) in enumerate(our_df.iterrows()):
        product = str(row.get(our_col,"")).strip()
        if not product or is_sample(product):
            if progress_callback: progress_callback((i+1)/total)
            continue

        our_price = 0.0
        if our_price_col:
            try: our_price = float(str(row[our_price_col]).replace(",",""))
            except: pass

        our_id  = _pid(row, our_id_col)
        brand   = extract_brand(product)
        size    = extract_size(product)
        ptype   = extract_type(product)
        gender  = extract_gender(product)
        our_n   = normalize(product)
        our_pl  = extract_product_line(product, brand)

        # â”€â”€ Ø¬Ù…Ø¹ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ù…Ù† ÙƒÙ„ Ø§Ù„ÙÙ‡Ø§Ø±Ø³ â”€â”€
        all_cands = []
        for idx_obj in indices.values():
            all_cands.extend(idx_obj.search(our_n, brand, size, ptype, gender, our_pline=our_pl, top_n=5))

        if not all_cands:
            results.append(_row(product,our_price,our_id,brand,size,ptype,gender,
                                None,"ğŸ”µ Ù…ÙÙ‚ÙˆØ¯ Ø¹Ù†Ø¯ Ø§Ù„Ù…Ù†Ø§ÙØ³"))
            if progress_callback: progress_callback((i+1)/total)
            continue

        all_cands.sort(key=lambda x: x["score"], reverse=True)
        top5  = all_cands[:5]
        best0 = top5[0]

        if best0["score"] >= 97 or not use_ai:
            # ÙˆØ§Ø¶Ø­ ØªÙ…Ø§Ù…Ø§Ù‹ â†’ Ù„Ø§ Ø­Ø§Ø¬Ø© AI
            results.append(_row(product,our_price,our_id,brand,size,ptype,gender,
                                best0,src="auto",all_cands=all_cands))
        else:
            # ØºØ§Ù…Ø¶ â†’ AI batch
            pending.append(dict(product=product,our_price=our_price,our_id=our_id,
                                brand=brand,size=size,ptype=ptype,gender=gender,
                                candidates=top5,all_cands=all_cands,
                                our=product,price=our_price))
            if len(pending) >= BATCH: _flush()

        if progress_callback: progress_callback((i+1)/total)

    _flush()
    return pd.DataFrame(results)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def find_missing_products(our_df, comp_dfs):
    our_col  = _fcol(our_df, ["Ø§Ù„Ù…Ù†ØªØ¬","Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬","Product","Name","name"])
    our_norms = [normalize(str(r.get(our_col,"")))
                 for _,r in our_df.iterrows()
                 if not is_sample(str(r.get(our_col,"")))]

    missing, seen = [], set()
    for cname, cdf in comp_dfs.items():
        ccol = _fcol(cdf, ["Ø§Ù„Ù…Ù†ØªØ¬","Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬","Product","Name","name"])
        icol = _fcol(cdf, ["ID","id","Ù…Ø¹Ø±Ù","Ø±Ù‚Ù… Ø§Ù„Ù…Ù†ØªØ¬","SKU","sku","Ø§Ù„ÙƒÙˆØ¯","code"])
        for _, row in cdf.iterrows():
            cp = str(row.get(ccol,"")).strip()
            if not cp or is_sample(cp): continue
            cn = normalize(cp)
            if not cn or cn in seen: continue
            match = rf_process.extractOne(cn, our_norms, scorer=fuzz.token_sort_ratio, score_cutoff=70)
            if match: continue
            seen.add(cn)
            sz = extract_size(cp)
            missing.append({
                "Ù…Ù†ØªØ¬_Ø§Ù„Ù…Ù†Ø§ÙØ³": cp, "Ù…Ø¹Ø±Ù_Ø§Ù„Ù…Ù†Ø§ÙØ³": _pid(row,icol),
                "Ø³Ø¹Ø±_Ø§Ù„Ù…Ù†Ø§ÙØ³": _price(row), "Ø§Ù„Ù…Ù†Ø§ÙØ³": cname,
                "Ø§Ù„Ù…Ø§Ø±ÙƒØ©": extract_brand(cp),
                "Ø§Ù„Ø­Ø¬Ù…": f"{int(sz)}ml" if sz else "",
                "Ø§Ù„Ù†ÙˆØ¹": extract_type(cp), "Ø§Ù„Ø¬Ù†Ø³": extract_gender(cp),
                "ØªØ§Ø±ÙŠØ®_Ø§Ù„Ø±ØµØ¯": datetime.now().strftime("%Y-%m-%d"),
            })
    return pd.DataFrame(missing) if missing else pd.DataFrame()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ØªØµØ¯ÙŠØ± Excel Ù…Ù„ÙˆÙ‘Ù†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def export_excel(df, sheet_name="Ø§Ù„Ù†ØªØ§Ø¦Ø¬"):
    from openpyxl.styles import PatternFill, Font, Alignment
    from openpyxl.utils import get_column_letter
    output = io.BytesIO()
    edf = df.copy()
    for col in ["Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†","Ø¬Ù…ÙŠØ¹_Ø§Ù„Ù…Ù†Ø§ÙØ³ÙŠÙ†"]:
        if col in edf.columns: edf = edf.drop(columns=[col])
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        edf.to_excel(writer, sheet_name=sheet_name[:31], index=False)
        ws = writer.sheets[sheet_name[:31]]
        hfill = PatternFill("solid", fgColor="1a1a2e")
        hfont = Font(color="FFFFFF", bold=True, size=10)
        for cell in ws[1]:
            cell.fill=hfill; cell.font=hfont
            cell.alignment=Alignment(horizontal="center")
        COLORS = {"ğŸ”´ Ø³Ø¹Ø± Ø£Ø¹Ù„Ù‰":"FFCCCC","ğŸŸ¢ Ø³Ø¹Ø± Ø£Ù‚Ù„":"CCFFCC",
                  "âœ… Ù…ÙˆØ§ÙÙ‚":"CCFFEE","âš ï¸ Ù…Ø±Ø§Ø¬Ø¹Ø©":"FFF3CC","ğŸ”µ Ù…ÙÙ‚ÙˆØ¯":"CCE5FF"}
        dcol = None
        for i, cell in enumerate(ws[1], 1):
            if cell.value and "Ø§Ù„Ù‚Ø±Ø§Ø±" in str(cell.value): dcol=i; break
        if dcol:
            for ri, row in enumerate(ws.iter_rows(min_row=2), 2):
                val = str(ws.cell(ri,dcol).value or "")
                for k,c in COLORS.items():
                    if k.split()[0] in val:
                        for cell in row: cell.fill=PatternFill("solid",fgColor=c)
                        break
        for ci, col in enumerate(ws.columns, 1):
            w = max(len(str(c.value or "")) for c in col)
            ws.column_dimensions[get_column_letter(ci)].width = min(w+4, 55)
    return output.getvalue()

def export_section_excel(df, sname):
    return export_excel(df, sheet_name=sname[:31])
